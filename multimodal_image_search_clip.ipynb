{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238520e0",
   "metadata": {},
   "source": [
    "# Multimodal search with CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3590f0e",
   "metadata": {},
   "source": [
    "In this notebook we show-case SuperDuperDB's functionality for searching with multiple types of data over\n",
    "the same `VectorIndex`. This comes out very naturally, due to the fact that SuperDuperDB allows\n",
    "users and developers to add arbitrary models to SuperDuperDB, and (assuming they output vectors) use\n",
    "these models at search/ inference time, to vectorize diverse queries.\n",
    "\n",
    "To this end, we'll be using the [CLIP multimodal architecture](https://openai.com/research/clip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/CLIP\n",
    "!pip install datasets\n",
    "!pip install superduperdb==0.0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f94ae8",
   "metadata": {},
   "source": [
    "So let's start. \n",
    "\n",
    "SuperDuperDB supports MongoDB as a databackend. Correspondingly, we'll import the python MongoDB client `pymongo`\n",
    "and \"wrap\" our database to convert it to a SuperDuper `Datalayer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5ef986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Vector database URI is the same as the data backend URI. Using the data backend as the vector database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating artifact store directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from superduperdb import CFG\n",
    "from superduperdb.db.base.build import build_datalayer\n",
    "from superduperdb.db.mongodb.query import Collection\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017/documents\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "CFG.data_backend = mongodb_uri\n",
    "CFG.artifact_store = 'filesystem://./models'\n",
    "CFG.vector_search = mongodb_uri\n",
    "\n",
    "db = build_datalayer(CFG)\n",
    "\n",
    "collection = Collection(name='tiny-imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6d6b0",
   "metadata": {},
   "source": [
    "In order to make this notebook easy to execute an play with, we'll use a sub-sample of the [Tiny-Imagenet\n",
    "dataset](https://paperswithcode.com/dataset/tiny-imagenet). \n",
    "\n",
    "Everything we are doing here generalizes to much larger datasets, with higher resolution images, without\n",
    "further ado. For such use-cases, however, it's advisable to use a machine with a GPU, otherwise they'll \n",
    "be some significant thumb twiddling to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29386a5",
   "metadata": {},
   "source": [
    "To get the images into the database, we use the `Encoder`-`Document` framework. This allows\n",
    "us to save Python class instances as blobs in the `Datalayer`, but retrieve them as Python objects.\n",
    "This makes it far easier to integrate Python AI-models with the datalayer.\n",
    "\n",
    "To this end, SuperDuperDB contains pre-configured support for `PIL.Image` instances. It's also \n",
    "possible to create your own encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.document import Document as D\n",
    "from superduperdb.ext.pillow.image import pil_image as i\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "dataset = load_dataset(\"zh-plus/tiny-imagenet\")['valid']\n",
    "dataset = [D({'image': i(r['image'])}) for r in dataset]\n",
    "dataset = random.sample(dataset, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7e282",
   "metadata": {},
   "source": [
    "The wrapped python dictionaries may be inserted directly to the `Datalayer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(collection.insert_many(dataset, encoders=(i,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d37264",
   "metadata": {},
   "source": [
    "We can verify that the images are correctly stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = db.execute(collection.find_one()).unpack()['image']\n",
    "display(x.resize((300, 300 * int(x.size[1] / x.size[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab27b50",
   "metadata": {},
   "source": [
    "We now can wrap the CLIP model, to ready it for multimodel search. It involves 2 components:\n",
    "\n",
    "- text-encoding\n",
    "- visual-encoding\n",
    "\n",
    "Once we have installed both parts, we will be able to search with both images and text for \n",
    "matching items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916792d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from superduperdb.ext.vector.encoder import vector\n",
    "from superduperdb.ext.torch.model import TorchModel\n",
    "import torch\n",
    "\n",
    "model, preprocess = clip.load(\"RN50\", device='cpu')\n",
    "\n",
    "e = vector(shape=(1024,))\n",
    "\n",
    "text_model = TorchModel(\n",
    "    identifier='clip_text',\n",
    "    object=model,\n",
    "    preprocess=lambda x: clip.tokenize(x)[0],\n",
    "    forward_method='encode_text',\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    encoder=e,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f82a69-caa3-4783-a015-2034540edc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.predict('This is a test', one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb08cc",
   "metadata": {},
   "source": [
    "Similar procedure with the visual part, which takes `PIL.Image` instances as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_model = TorchModel(\n",
    "    identifier='clip_image',\n",
    "    preprocess=preprocess,\n",
    "    object=model.visual,\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    encoder=e,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_model.predict(x, one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716bcb2",
   "metadata": {},
   "source": [
    "Now let's create the index for searching by vector. We register both models with the index simultaneously,\n",
    "but specifying that it's the `visual_model` which will be responsible for creating the vectors in the database\n",
    "(`indexing_listener`). The `compatible_listener` specifies how one can use an alternative model to search \n",
    "the vectors. By using models which expect different types of index, we can implement multimodal search\n",
    "without further ado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.vector_index import VectorIndex\n",
    "from superduperdb.container.listener import Listener\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        'my-index',\n",
    "        indexing_listener=Listener(\n",
    "            model=visual_model,\n",
    "            key='image',\n",
    "            select=collection.find(),\n",
    "        ),\n",
    "        compatible_listener=Listener(\n",
    "            model=text_model,\n",
    "            key='text',\n",
    "            active=False,\n",
    "            select=None,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18971a6d",
   "metadata": {},
   "source": [
    "We can now demonstrate searching by text for images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab994b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from IPython.display import display\n",
    "from superduperdb.container.document import Document as D\n",
    "\n",
    "out = db.execute(\n",
    "    collection.like(D({'text': 'mushroom'}), vector_index='my-index', n=3).find({})\n",
    ")\n",
    "for r in out:\n",
    "    x = r['image'].x\n",
    "    display(x.resize((300, 300 * int(x.size[1] / x.size[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f07a8b7-a8a2-483b-87e3-a5408efb3ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/246886f2fd18461790e316c3139a6578'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclip_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/db/base/db.py:502\u001b[0m, in \u001b[0;36mDB.load\u001b[0;34m(self, type_id, identifier, version, allow_hidden, info_only)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[1;32m    501\u001b[0m info \u001b[38;5;241m=\u001b[39m replace_children(info)\n\u001b[0;32m--> 502\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mload_artifacts_from_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact_store\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m m \u001b[38;5;241m=\u001b[39m Component\u001b[38;5;241m.\u001b[39mdeserialize(info)\n\u001b[1;32m    507\u001b[0m m\u001b[38;5;241m.\u001b[39mon_load(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/container/artifact_tree.py:80\u001b[0m, in \u001b[0;36mload_artifacts_from_store\u001b[0;34m(tree, cache, artifact_store)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     make \u001b[38;5;241m=\u001b[39m artifact_store\u001b[38;5;241m.\u001b[39mload_artifact\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/container/artifact_tree.py:118\u001b[0m, in \u001b[0;36m_load_artifacts\u001b[0;34m(tree, make, cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m     cache[file_id] \u001b[38;5;241m=\u001b[39m Artifact(artifact\u001b[38;5;241m=\u001b[39martifact, info\u001b[38;5;241m=\u001b[39minfo, serializer\u001b[38;5;241m=\u001b[39mserializer)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[file_id]\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_has_file_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewrite\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/data/tree/tree.py:46\u001b[0m, in \u001b[0;36mtree_rewrite\u001b[0;34m(tree, accept, rewrite)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_rewrite(t, accept, rewrite) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewrite\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/data/tree/tree.py:46\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_rewrite(t, accept, rewrite) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[43mtree_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewrite\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/data/tree/tree.py:46\u001b[0m, in \u001b[0;36mtree_rewrite\u001b[0;34m(tree, accept, rewrite)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_rewrite(t, accept, rewrite) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewrite\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/data/tree/tree.py:46\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_rewrite(t, accept, rewrite) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[43mtree_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewrite\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/data/tree/tree.py:42\u001b[0m, in \u001b[0;36mtree_rewrite\u001b[0;34m(tree, accept, rewrite)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates recursively through lists and dicts, rewriting all leaves `x`\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m   where `accept(x)` is True with `rewrite(x)`\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m:param rewrite: A function which rewrites accepted values\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept(tree):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_rewrite(t, accept, rewrite) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree]\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/container/artifact_tree.py:114\u001b[0m, in \u001b[0;36m_load_artifacts.<locals>.rewrite\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    113\u001b[0m info, serializer \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m), t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserializer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 114\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m cache[file_id] \u001b[38;5;241m=\u001b[39m Artifact(artifact\u001b[38;5;241m=\u001b[39martifact, info\u001b[38;5;241m=\u001b[39minfo, serializer\u001b[38;5;241m=\u001b[39mserializer)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[file_id]\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/db/base/artifact.py:63\u001b[0m, in \u001b[0;36mArtifactStore.load_artifact\u001b[0;34m(self, file_id, serializer, info)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_id: \u001b[38;5;28mstr\u001b[39m, serializer: \u001b[38;5;28mstr\u001b[39m, info: Info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    Load artifact from artifact store, and deserialize.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    :param file_id: Identifier of artifact in the store\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    :param serializer: Serializer to use for deserialization\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     serializer_function \u001b[38;5;241m=\u001b[39m serializers[serializer]\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serializer_function\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mbytes\u001b[39m, info)\n",
      "File \u001b[0;32m~/SuperDuperDB/superduperdb-examples/.venv/lib/python3.11/site-packages/superduperdb/db/filesystem/artifacts.py:59\u001b[0m, in \u001b[0;36mFileSystemArtifactStore._load_bytes\u001b[0;34m(self, file_id)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/246886f2fd18461790e316c3139a6578'"
     ]
    }
   ],
   "source": [
    "m = db.load('model', 'clip_text')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
