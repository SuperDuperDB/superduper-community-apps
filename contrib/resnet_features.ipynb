{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c245fde",
   "metadata": {},
   "source": [
    "# Building an Image Feature Database in `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ce76a-398f-4064-95d8-c7f0a399d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install superduperdb==0.0.12\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df884338",
   "metadata": {},
   "source": [
    "In this example, we show how to utilize a pre-trained network from `torchvision` to produce image features. The images are automatically fetched and stored in MongoDB. We use a subset of the CoCo dataset (https://cocodataset.org/#home) to illustrate the process.\n",
    "\n",
    "Real-life use cases for creating a database of image features using a pre-trained network in `torchvision`:\n",
    "\n",
    "1. **Image Search and Retrieval:**\n",
    "   \n",
    "   - **Use Case:** Enhance image search capabilities in e-commerce platforms.\n",
    "   - **How:** Generate image features for products using a pre-trained network. Store these features in a database for efficient image retrieval, making it easier for users to find similar products.\n",
    "\n",
    "2. **Content-Based Recommendation Systems:**\n",
    "   \n",
    "   - **Use Case:** Improve content recommendations in media streaming services.\n",
    "   - **How:** Extract image features from movie or show frames. Store these features in a database to recommend content with similar visual characteristics to users based on their preferences.\n",
    "\n",
    "3. **Facial Recognition in Security Systems:**\n",
    "   \n",
    "   - **Use Case:** Strengthen facial recognition systems in security applications.\n",
    "   - **How:** Utilize a pre-trained neural network to extract facial features from images. Store these features in a database for quick and accurate identification in security and surveillance scenarios.\n",
    "\n",
    "4. **Medical Image Analysis:**\n",
    "   \n",
    "   - **Use Case:** Assist in medical diagnostics through image analysis.\n",
    "   - **How:** Extract features from medical images (X-rays, MRIs, etc.) using a pre-trained network. Store these features to aid in the development of diagnostic tools or systems for healthcare professionals.\n",
    "\n",
    "5. **Automated Image Tagging:**\n",
    "   \n",
    "   - **Use Case:** Streamline image organization in photo libraries or social media platforms.\n",
    "   - **How:** Extract features from uploaded images using a pre-trained model. Use these features to automatically generate relevant tags, making it easier for users to search and categorize their photos.\n",
    "\n",
    "These use cases demonstrate how creating a database of image features using `torchvision` can be applied across various domains to enhance functionality and improve user experiences. Guess what, all can be done with `superduperdb` like this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/valsmall2014.zip\n",
    "!unzip -qq valsmall2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0351da",
   "metadata": {},
   "source": [
    "As usual, we create an instance of the `Datalayer` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from superduperdb import superduper\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017\"\n",
    "# mongodb_uri = \"mongodb://superduper:superduper@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from superduperdb import superduper\n",
    "db = superduper(mongodb_uri)\n",
    "\n",
    "collection = Collection('coco')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c903f2",
   "metadata": {},
   "source": [
    "Next, we include all image URIs in MongoDB. These URIs may include a mix of local file paths (`file://...`), web URLs (`http...`), and S3 URIs (`s3://...`). Once the URIs are added, SuperDuperDB automatically loads their content into MongoDB without the need for extra overhead or job definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "from superduperdb import Document as D\n",
    "from superduperdb.ext.pillow import pil_image as i\n",
    "\n",
    "uris = [f'file://{x}' for x in glob.glob('valsmall2014/*.jpg')]\n",
    "\n",
    "db.execute(collection.insert_many([D({'img': i(uri=uri)}) for uri in uris], encoders=(i,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3a73e",
   "metadata": {},
   "source": [
    "To confirm the correct storage of images in the `Datalayer`, we can perform a verification check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Jupyter often crashes with bigger images\n",
    "display_image = lambda x: display(x.resize((round(x.size[0] * 0.5), round(x.size[1] * 0.5))))\n",
    "\n",
    "x = db.execute(collection.find_one())['img'].x\n",
    "\n",
    "display_image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d696ca",
   "metadata": {},
   "source": [
    "Let's build the `torch` + `torchvision` model using the `TorchModel` wrapper from SuperDuperDB. This allows for the incorporation of custom pre- and post-processing steps along with the model's forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43639f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "\n",
    "from superduperdb.ext.torch import TorchModel, tensor\n",
    "\n",
    "t = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess(x):\n",
    "    try:\n",
    "        return t(x)\n",
    "    except Exception as e:\n",
    "        warnings.warn(str(e))\n",
    "        return torch.zeros(3, 224, 224)\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules = list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "\n",
    "model = TorchModel(\n",
    "    identifier='resnet50',\n",
    "    preprocess=preprocess,\n",
    "    object=resnet50,\n",
    "    postprocess=lambda x: x[:, 0, 0],\n",
    "    encoder=tensor(torch.float, shape=(2048,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34454fa",
   "metadata": {},
   "source": [
    "To ensure the correctness of the `model`, let's test it on a single data point by setting `one=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa87aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x, one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48cb81a",
   "metadata": {},
   "source": [
    "Now that the model is prepared, we can apply it to the images stored in the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\n",
    "    X='img',\n",
    "    db=db,\n",
    "    select=collection.find(),\n",
    "    batch_size=10,\n",
    "    max_chunk_size=3000,\n",
    "    in_memory=False,\n",
    "    listen=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67880a",
   "metadata": {},
   "source": [
    "To confirm that the features were stored in the `Datalayer`, you can examine them in the `_outputs.img.resnet50` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(collection.find_one()).unpack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
